<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Startup-analysis : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
<link href="lightbox2-master/src/css/lightbox.css" rel="stylesheet">

    <title>Predicting Startup Funding Via Twitter</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/kyang01/startup-analysis">View on GitHub</a>

          <h1 id="project_title">Predicting Startup Funding Via Twitter</h1>
          <h4 class="project_tagline">JKMR Data</h4>
          <h4 class="project_tagline">Roger Zou, Melody Guan, Kevin Yang, Jerry Anunrojwong</h4>
          <a class='shortcut' href="https://kyang01.github.io/startup-analysis#video">Screencast</a>
          &emsp; &emsp; &emsp; &emsp;<a class='shortcut' href="https://kyang01.github.io/startup-analysis#overview">Overview</a>
          &emsp; &emsp; &emsp; &emsp;<a class='shortcut' href="https://kyang01.github.io/startup-analysis#analysis">Analysis</a>
          &emsp; &emsp; &emsp; &emsp;<a class='shortcut' href="https://kyang01.github.io/startup-analysis#predictions">Predictions</a>
            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/kyang01/startup-analysis/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/kyang01/startup-analysis/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
      <div id="video">
<iframe width="560" height="315" src="https://www.youtube.com/embed/4JwMyLHcCYI" frameborder="0" allowfullscreen></iframe>
</div>
      
      <h2>
<a id="overview" class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h2>

<h3>Motivation and Goals</h3>

<!--a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h3>
Overview</h3>
-->
<p>Does more effective publicizing lead to better fundraising results for a startup? We propose to test the converse: Before financing rounds, might there be an abnormal amount of PR activity? Can we predict details on events like financing rounds based on mentions of a company on social media platforms like Twitter? Or is social media a noisy, meaningless indicator?</p>
<p>This project aims to use data analysis and predictive analytics to find correlations between tweets and startup funding rounds in order to shed light on potential importance of tweets and social media in general as indicators of startup success. Through a variety of models, we show that there is a relationship between tweets and startup funding.</p>

<h2>
<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Collection</h2>
          
<h3>Startup Fundings</h3>

<p>We've downloaded our list of startups and their funding round info from <a href="https://angel.co/">AngelList</a>, a US website with extensive startup financial data. AngelList did not have an API, so we used the urllib2 Requests library to download each search page, then used BeautifulSoup to parse the page. The data is located in the <a href="https://github.com/kyang01/startup-analysis/tree/master/data">data</a> folder.</p>

<h3>Tweets</h3>

<p> We downloaded our tweets by directly scraping <a href="https://twitter.com">Twitter</a> for mentions of startups on our list. While Twitter does have an API, its Search API is limited to an index of 6-9 days of tweets and its Timeline API is limited to up to 3200 tweets per timeline, not to mention rate limits on scraping both. We did initially write a <a href="https://github.com/kyang01/startup-analysis/blob/d98e6455038abec2d97097eb3009fd04c508799d/Mining-the-Social-Web-2nd-Edition/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb">code that used the API</a>, but decided instead to scrape via the Twitter <a href="https://twitter.com/search?q=">search page</a> with Selenium Webdriver browser scripts and BeautifulSoup. The tweets are located in the <a href="https://github.com/kyang01/startup-analysis/tree/master/data">data</a> folder.</p>

<h3>Translating Tweets</h3>

<p>The majority of our tweets were non-English, necessiting us to translate them in order to get an accurate model that works globally, not just for US startups. After filtering English tweets with the <a href="https://bitbucket.org/spirit/guess_language">guess_language</a> python library, we used the <a href="https://pypi.python.org/pypi/microsofttranslator/0.7">Microsoft Translator API</a> to translate all our tweets.</p>

<h2>
<a id="analysis" class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploratory Data Analysis</h2>


<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Startup Financial Analysis</h3>
<p>After preliminary analysis, we determined that the average Series A funding round is approximately $6 million, the average Series B funding round is $11 million, the average Series C funding round is $16 million, and the average Series D funding round is around $17 million dollars. However, there is significant variance in the amount of money each company raises. Graphing it on a scale from 0 to $100 million, we see all Series are very much skewed right.</p>


<a href="images/series_funding.png" data-lightbox="avf" data-title="avf"><img src="images/series_funding.png" style="height:300px;"></a>

<p>However, once we plot the log of the data instead, we are able to get a distribution that looks much less skewed and that we can treat as similar to normal.</p>


<a href="images/series_funding_log.png" data-lightbox="avf" data-title="avf"><img src="images/series_funding_log.png" style="height:300px;"></a>


<h2>
    <a class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feature Extraction</h2>

<h3>Features from Tweet Metadata</h3>
<p>
We  extracted features from Twitter metadata such as: the number of likes, the number of retweets, the date tweeted for each tweet. We grouped these by (company, funding_round) combination and compute the mean and standard deviation for each pair. We created features from these dates by computing the range of dates spanned among our ~200 tweets scraped, and the interquartile range. The intuition is that even though we can't scrape all the tweets made, if the range of dates are wide, given the fixed amount of tweets, then the tweets are made relatively infrequently. This might have some predictive power.
</p>


<h3>Features from Tweet Text</h3>
<p>
Apart from metadata, we extracted a number of features from the text in the tweet itself. We computed text length, the number of hashtags, the number of persontags (tags of other Twitter accounts, beginning with @), the number of links, the proportion of tweets made by the company itself versus other people, the number of times tweets are directed toward the company.
</p>


<h3>Features from Funding Series and Market Sectors</h3> 
<p>
We created an indicator variable for each of the 4 funding rounds (A,B,C,D). When we looked at the market sector data (that we get from scraping) we see that some sectors have a lot of companies in it (such as Biotech, has around 300) while most categories have very few (mostly less than 10). These categories that have few companies are not very useful because they are too dispersed and specific, but we think the top sectors that have a lot of companies are more useful, so we create indicator variables for top 10 sectors.
</p>

<h2>
    <a class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Exploration and Feature Selection</h2>
 
<h3>Natural Language Processing</h3>

We parsed the text in each tweet using the pattern python library to extract nouns and adjectives. We removed punctuation and stopwords (from sklearn). We decided not to assign topics using LDA due to the heterogeneity of our tweets. We parsed the text into sentences and then tokenized the sentences into words. We then lemmatized the words, which means that we convert words into their basic form, for example: "walk", "walking", "walks", "walked" => "walk". Because each tweet is short (maximum 140 characters) we did not distinguish between sentences within tweets. 

<h3>Sentiment Analysis</h3>
<p>
  We used the sentiment dictionary SentiWordNet 3.0, which assigns to words (both nouns and adjectives) three sentiment scores: positivity, negativity, objectivity. For each tweet, we took the average positivity score over all tokens and the average negativity score over all tokens. We also defined a word as "positive" or "negative" if it had positivity score>0.5 or negativity score>0.5 respectively. For each tweet, we then summed up the total "positive" words and total "negative" words (usually 0,1, and rarely 2). To summarize, we have four features from sentiment analysis: average positivity, average negativity, positive count, negative count. For each company, funding round pair, we then take the average of these features for all their tweets.
</p>
          
<h3>Correlation Analysis</h3>
<p>In this analysis, we only considered the 1200 startups that had more than 150 tweets and valid dates. With and without scaling both parameters, our results were mostly inconclusive. While some scaled v. scaled graphs displayed homoscedastic behavior (equal variance across features), their slopes tended to be very close to 0 and not at all linear.</p>
<br/>
<p>We plotted the unscaled 'Amount Raised' against all unscaled numerical features, and found no linear correlations.</p>
<a href="images/amount_vs_features.png" data-lightbox="avf" data-title="avf"><img src="images/amount_vs_features.png" style="height:300px;"></a>
<p>We then plotted log of 'Amount Raised' against all numerical features normalized using Box Cox transformation (see PCA section), and again found no linear correlations.</p>
<a href="images/amount_vs_features_scaled.png" data-lightbox="avfs" data-title="avfs"><img src="images/amount_vs_features_scaled.png" style="height:300px;"></a>
<p>We did not find linear correlations for log of 'Amount Raised' against unscaled features either.</p>
<a href="images/scaled_amount_vs_features.png" data-lightbox="savf" data-title="savf"><img src="images/scaled_amount_vs_features.png" style="height:300px;" ></a>
<p>We did find some homoskedastic correlations for scaled 'Amount Raised' against scaled features', but unfortunately these slopes were flat.</p>
<a href="images/scaled_amount_vs_features_scaled.png" data-lightbox="savfs" data-title="savfs"><img src="images/scaled_amount_vs_features_scaled.png" style="height:300px;" ></a>
<p>From our correlation analysis, we infer that using SVR may be a better method for predictive modeling than linear regression.</p>
    
<h3>Principal Component Analysis</h3>
          
<p>Principal Component Analysis (PCA) tries to isolate a handful of linear combinations of features that "explain" most variances in the data. This is a descriptive, not predictive, technique, and it operates on the whole dataset without the training/testing division. Moreover, PCA is more informative if all features are suitably normalized, so no single feature can dominate the total variance. We therefore used Box Cox transformation on each column (the library chooses an appropriate parameter, different for each column, to make the resulting transformation approximately Normal.) The exception is the funding raised, which we use the log transformation (which is also a special case of Box Cox). This is justified because our plot shows that log(funding) looks Normal, and when we predict log(funding), reversing the function to get funding is more expedient. Our PCA shows that only a few (aggregated) features explain most of the variance. 3 top features explain 95% of the variance, while 5 top features explain 98% of the variance. The most important features appear to be number of favorites and retweets and the date range of the last 200 tweets.</p>


<a href="images/pca_explain_var.png" data-lightbox="avf" data-title="avf"><img src="images/pca_explain_var.png" style="height:300px;"></a>
          
<h2>
<a id="predictions" class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a>Predictive Modeling</h2>
          <h3>Baseline Predictions</h3>
<p>Based off just the Series data, we're able to predict funding round amounts naively by predicting the average Series amount. We find the root mean squared error to be approximately $10 million, a baseline prediction we'll use to compare to our later, more complex predictions.</p>
          
<h3> Linear Regression</h3>
          
<h3> Support Vector Regression (SVR) </h3>
<p> 
  We suspect that the problem is not linear, so we turn to Support Vector Regression (SVR).  We split the data into the training data and the testing data, standardize the numerical features of each of the two datasets separately. We try three choices of kernels - rbf, linear and polynomial. For each choice of kernal, we use GridSearchCV with 5-fold cross validation to find the optimal parameters of the predictor over a reasonable (pre-determined) range of parameters. We then fit the predictor to the training data, predict it on the test data, and evaluate it by computing RMSE on log(funding). We found that rbf predictor with C=100 and gamma=0.01 is the best, with RMSE around 1. This result is comparable to linear regression.
</p>

<h3> Neural Nets </h3>

<p> 
  In order to explore other methods that can identify nonlinear trends, we wanted to run neural nets as well.  Similar to the previous example, we used normalized variations of numerical data. The data we wanted to predict was the log of the series funding amounts. We worked with various python neural net libraries with limited success. Ultimately, we decided to work with Matlab to create a neural net. We used the neural net toolbox and created a neural net with one layer of 50 intermediate nodes. The neural net package provided by Matlab uses the Levenberg-Marquadrt algorithm to run. In the end, we were able to achieve an RMSE of 18.8. 

</p>

<a href="images/nn_results.png" data-lightbox="avf" data-title="avf"><img src="images/nn_results.png" style="height:300px;"></a>
<a href="images/nn_error.png" data-lightbox="avf" data-title="avf"><img src="images/nn_error.png" style="height:300px;"></a>


<h3>Root Mean Square Deviations</h3>
<table>
    <tr>
        <td><b>Type of Model</b></td>
        <td><b>RMSE Value</b></td>
    </tr>
    <tr>
        <td>Baseline</td>
        <td>118.2</td>
    </tr>
    <tr>
        <td>SVR RBF</td>
        <td>1.1</td>
    </tr>
    <tr>
        <td>SVR Linear</td>
        <td>10.9</td>
    </tr>
    <tr>
        <td>SVR Poly</td>
        <td>33.1</td>
    </tr>
    <tr>
        <td>Lasso Regression (R-sq = 0.15)</td>
        <td>18.3</td>
    </tr>
    <tr>
        <td>Ridge Regression (R-sq = 0.15)</td>
        <td>18.3</td>
    </tr>
    <tr>
        <td>Neural Net</td>
        <td>20.2</td>
    </tr>
</table>


<h3>
<a id="Conclusion" class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h3>

<p>Overall, each of our models did better than our baseline predictions. In particular, SVR with an radial basis function kernel performed best, followed by SVR with a linear kernel, and then Ridge and Lasso regression. </p>

<p>In the future, we would perform more clustering to obtain more tailored forecasts with regard to company sizes and industries, and combine Twitter with other signals to achieve better predictions of funding success.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
      <p class="copyright">This project is maintained by <a href="https://github.com/kyang01">kyang01</a> with support from <a href="https://github.com/rogergzou">rogergzou</a> and <a href="https://github.com/jerryinfinity">jerryinfinity</a> and Melody</p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a> for Harvard's CS109 Data Science Final Project</p>
      </footer>
    </div>

<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.4/jquery.min.js"></script>
    
<script src="path/to/lightbox.js"></script>

  </body>
</html>
